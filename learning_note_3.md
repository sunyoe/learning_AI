
NLP方向  
task6   批量归一化和残差网络  
Resnet网络和Desnet网络的区别在于：前者最后是相加，两个结果的大小需要一致，如果不一致则使用一些方法修改大小；desnet则是合并成一个新的向量，因此两个结果的通道数可以不一样。  
如果使用nn元语法模型存在数据稀疏问题，最终计算出来的大部分参数都是0  
        凸优化  
        梯度下降  
随机梯度下降的时间复杂度是O(1)  
牛顿法;牛顿法相比梯度下降的一个优势在于：梯度下降“步幅”的确定比较困难，而牛顿法相当于可以通过Hessian矩阵来调整“步幅”。牛顿法需要计算Hessian矩阵的逆，计算量比较大。在牛顿法中，局部极小值也可以通过调整学习率来解决。  
可以通过修改 train_sgd 函数的参数batch_size来分别使用梯度下降、随机梯度下降和小批量随机梯度下降。  
        
task7   优化算法进阶   
        word2vec  
        词嵌入进阶  
        
task8   文本分类  
        数据增强  
        模型微调  
        
CV方向  
task9   目标检测基础  
        图像风格迁移  
        图像分类案例1  
        
task10  图像分类案例2  
        GAN  
        DCGAN  
